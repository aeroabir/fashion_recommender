{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance Item Features by Graph Neural Network\n",
    "\n",
    "    - use the image embedding vector (from EfficientNet) and text embedding vectors (from BERT)\n",
    "    - use Graph Attention Network for subsequent feature transformation\n",
    "    - use outfit definition as edges (two items are connected if they are part of the same outfit), use only the training data\n",
    "    - use category-id as node label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "import shap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data.loaders import SingleLoader\n",
    "from spektral.datasets.citation import Citation\n",
    "from spektral.layers import GATConv, GCSConv, GlobalAvgPool\n",
    "from spektral.transforms import LayerPreprocess\n",
    "from spektral.data import Dataset, DisjointLoader, Graph\n",
    "from spektral.transforms.normalize_adj import NormalizeAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.datasets.citation import Citation\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import LayerPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cora dataset.\n",
      "Pre-processing node features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n"
     ]
    }
   ],
   "source": [
    "dataset = Citation(\"cora\", normalize_x=True, transforms=[LayerPreprocess(GCNConv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'a',\n",
       " 'apply',\n",
       " 'available_datasets',\n",
       " 'download',\n",
       " 'dtype',\n",
       " 'filter',\n",
       " 'graphs',\n",
       " 'map',\n",
       " 'mask_te',\n",
       " 'mask_tr',\n",
       " 'mask_va',\n",
       " 'n_edge_features',\n",
       " 'n_graphs',\n",
       " 'n_labels',\n",
       " 'n_node_features',\n",
       " 'n_nodes',\n",
       " 'name',\n",
       " 'normalize_x',\n",
       " 'path',\n",
       " 'random_split',\n",
       " 'read',\n",
       " 'signature',\n",
       " 'suffixes',\n",
       " 'url']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2708, 1433, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n_graphs, dataset.n_nodes, dataset.n_node_features, dataset.n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create node and edge matrix from Outfit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/polyvore_outfits\"\n",
    "data_type = \"nondisjoint\" # \"disjoint\"\n",
    "train_dir = os.path.join(base_dir, data_type)\n",
    "image_dir = os.path.join(base_dir, \"images\")\n",
    "train_json = \"train.json\"\n",
    "valid_json = \"valid.json\"\n",
    "test_json = \"test.json\"\n",
    "\n",
    "train_file = \"compatibility_train.txt\"\n",
    "valid_file = \"compatibility_valid.txt\"\n",
    "test_file = \"compatibility_test.txt\"\n",
    "item_file = \"polyvore_item_metadata.json\"\n",
    "outfit_file = \"polyvore_outfit_titles.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_dir, train_json), 'r') as fr:\n",
    "    train_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(train_dir, valid_json), 'r') as fr:\n",
    "    valid_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(train_dir, test_json), 'r') as fr:\n",
    "    test_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(base_dir, item_file), 'r') as fr:\n",
    "    pv_items = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(base_dir, outfit_file), 'r') as fr:\n",
    "    pv_outfits = json.load(fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_dir, train_file), 'r') as fr:\n",
    "    train_X, train_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        train_y.append(elems[0])\n",
    "        train_X.append(elems[1:])\n",
    "\n",
    "with open(os.path.join(train_dir, valid_file), 'r') as fr:\n",
    "    valid_X, valid_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        valid_y.append(elems[0])\n",
    "        valid_X.append(elems[1:])\n",
    "\n",
    "with open(os.path.join(train_dir, test_file), 'r') as fr:\n",
    "    test_X, test_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        test_y.append(elems[0])\n",
    "        test_X.append(elems[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53306 outfits in train, 5000 outfits in validation and 10000 outfits in the test data\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_pos)} outfits in train, {len(valid_pos)} outfits in validation and {len(test_pos)} outfits in the test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dict that maps to the original item-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 284767\n",
      "Train & Validation data: 311548\n",
      "Train, validation and test data 365054\n"
     ]
    }
   ],
   "source": [
    "item_dict = {}\n",
    "for ii, outfit in enumerate(train_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = train_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(\"Train data:\", len(item_dict))\n",
    "\n",
    "for ii, outfit in enumerate(valid_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = valid_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(\"Train & Validation data:\", len(item_dict))\n",
    "\n",
    "for ii, outfit in enumerate(test_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = test_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(\"Train, validation and test data\", len(item_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 204679 items in the train data\n",
      "Total 25132 items in the valid data\n",
      "9356 common items between train and validation set\n",
      "Total 47854 items in the test data\n",
      "16655 common items between train and test set\n"
     ]
    }
   ],
   "source": [
    "train_set = set()\n",
    "for outfit in train_pos:\n",
    "    items = [x['item_id'] for x in outfit['items']]\n",
    "    train_set |= set(items)\n",
    "print(f\"Total {len(train_set)} items in the train data\")\n",
    "\n",
    "valid_set = set()\n",
    "for outfit in valid_pos:\n",
    "    items = [x['item_id'] for x in outfit['items']]\n",
    "    valid_set |= set(items)\n",
    "print(f\"Total {len(valid_set)} items in the valid data\")\n",
    "print(f\"{len(valid_set.intersection(train_set))} common items between train and validation set\")\n",
    "\n",
    "test_set = set()\n",
    "for outfit in test_pos:\n",
    "    items = [x['item_id'] for x in outfit['items']]\n",
    "    test_set |= set(items)\n",
    "print(f\"Total {len(test_set)} items in the test data\")\n",
    "print(f\"{len(test_set.intersection(train_set))} common items between train and test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/precomputed\"\n",
    "with open(os.path.join(embed_dir, \"effnet2_polyvore.pkl\"), \"rb\") as fr:\n",
    "    image_embedding = pickle.load(fr)\n",
    "    \n",
    "with open(os.path.join(embed_dir, \"bert_polyvore.pkl\"), \"rb\") as fr:\n",
    "    text_embedding = pickle.load(fr)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261057"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_item_categories = set([pv_items[item]['category_id'] for item in pv_items])\n",
    "len(all_item_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_renum_dict = {}\n",
    "for ii, k in enumerate(all_item_categories):\n",
    "    label_renum_dict[k] = ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node file has all the items (written as outfit-i_j) for the i-th outfit and j-th item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365054/365054 [07:25<00:00, 819.52it/s]\n"
     ]
    }
   ],
   "source": [
    "node_file, edge_file = f\"nodes_{data_type}.txt\", f\"edges_{data_type}.txt\"\n",
    "fn = open(os.path.join(train_dir, node_file), 'w')\n",
    "\n",
    "item_number_dict = {}  # converts item number to integers\n",
    "count = 0\n",
    "for item in tqdm(item_dict):\n",
    "    item_number_dict[item] = count\n",
    "    item_name = item_dict[item]\n",
    "    x_img = image_embedding[item_name].numpy().tolist()\n",
    "#     x_txt = text_embedding[item_name].tolist()\n",
    "    label = pv_items[item_name]['category_id']\n",
    "    label = label_renum_dict[label]\n",
    "    \n",
    "    out = [count] + x_img + [label]\n",
    "    out = \"\\t\".join([str(x) for x in out]) + \"\\n\"\n",
    "    fn.write(out)\n",
    "    count += 1\n",
    "\n",
    "fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199244701_1',\n",
       " '199244701_2',\n",
       " '199244701_3',\n",
       " '199244701_4',\n",
       " '199244701_5',\n",
       " '199244701_6']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edges based on Outfit Items\n",
    "\n",
    "    - if there are N items in an outfit then create N(N-1)/2 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for comb in itertools.combinations([1,2,3, 4], 2):\n",
    "    print(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53306/53306 [00:00<00:00, 54380.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 686851 edges written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "edge_file_train = f\"edges_{data_type}_train.txt\"\n",
    "fw = open(os.path.join(train_dir, edge_file_train), 'w')\n",
    "count = 0\n",
    "for ii in tqdm(range(len(train_pos))):\n",
    "    items = [item_number_dict[k] for k in train_X[ii]]\n",
    "    for comb in itertools.combinations(items, 2):\n",
    "        src, tgt = comb[1], comb[0]\n",
    "        fw.write(\"\\t\".join([str(tgt), str(src)]) + \"\\n\")\n",
    "        count += 1\n",
    "fw.close()\n",
    "print(f\"Total {count} edges written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 54245.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 64925 edges written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "edge_file_valid = f\"edges_{data_type}_valid.txt\"\n",
    "fw = open(os.path.join(train_dir, edge_file_valid), 'w')\n",
    "count = 0\n",
    "for ii in tqdm(range(len(valid_pos))):\n",
    "    items = [item_number_dict[k] for k in valid_X[ii]]\n",
    "    for comb in itertools.combinations(items, 2):\n",
    "        src, tgt = comb[1], comb[0]\n",
    "        fw.write(\"\\t\".join([str(tgt), str(src)]) + \"\\n\")\n",
    "        count += 1\n",
    "fw.close()\n",
    "print(f\"Total {count} edges written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 53702.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 129589 edges written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "edge_file_test = f\"edges_{data_type}_test.txt\"\n",
    "fw = open(os.path.join(train_dir, edge_file_test), 'w')\n",
    "count = 0\n",
    "for ii in tqdm(range(len(test_pos))):\n",
    "    items = [item_number_dict[k] for k in test_X[ii]]\n",
    "    for comb in itertools.combinations(items, 2):\n",
    "        src, tgt = comb[1], comb[0]\n",
    "        fw.write(\"\\t\".join([str(tgt), str(src)]) + \"\\n\")\n",
    "        count += 1\n",
    "fw.close()\n",
    "print(f\"Total {count} edges written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GraphSage Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365054, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(embed_dir, \"graphsage_polyvore_nondisjoint.pkl\"), \"rb\") as fr:\n",
    "    gs_embed = pickle.load(fr)\n",
    "gs_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graphsage number to outfit-item\n",
    "# example, id2item[365053] = '209553625_5'\n",
    "# and then, item_dict['209553625_5'] = '172852191' (original item-id)\n",
    "id2item = {}\n",
    "for key, value in item_number_dict.items():\n",
    "    id2item[value] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('209553625_5', 365053)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172852191'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_dict = {}\n",
    "for ii in range(gs_embed.shape[0]):\n",
    "    item = item_dict[id2item[ii]]\n",
    "    graphsage_dict[item] = gs_embed[ii]\n",
    "\n",
    "with open(os.path.join(embed_dir, \"graphsage_dict_polyvore_nondisjoint.pkl\"), \"wb\") as output_file:\n",
    "    pickle.dump(graphsage_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from stellargraph.data import UniformRandomWalk\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from stellargraph import globalvar\n",
    "\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68935</th>\n",
       "      <td>85929</td>\n",
       "      <td>85928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68936</th>\n",
       "      <td>85930</td>\n",
       "      <td>85929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68937</th>\n",
       "      <td>85931</td>\n",
       "      <td>85930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68938</th>\n",
       "      <td>85932</td>\n",
       "      <td>85931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68939</th>\n",
       "      <td>85934</td>\n",
       "      <td>85933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  source\n",
       "0           1       0\n",
       "1           2       1\n",
       "2           3       2\n",
       "3           4       3\n",
       "4           5       4\n",
       "...       ...     ...\n",
       "68935   85929   85928\n",
       "68936   85930   85929\n",
       "68937   85931   85930\n",
       "68938   85932   85931\n",
       "68939   85934   85933\n",
       "\n",
       "[68940 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = pd.read_csv(\n",
    "    os.path.join(train_dir, 'edges.txt'),\n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    header=None,  # no heading row\n",
    "    names=[\"target\", \"source\"],  # set our own names for the columns\n",
    ")[[\"target\", \"source\"]]\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X1271</th>\n",
       "      <th>X1272</th>\n",
       "      <th>X1273</th>\n",
       "      <th>X1274</th>\n",
       "      <th>X1275</th>\n",
       "      <th>X1276</th>\n",
       "      <th>X1277</th>\n",
       "      <th>X1278</th>\n",
       "      <th>X1279</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.062523</td>\n",
       "      <td>0.421099</td>\n",
       "      <td>-0.124768</td>\n",
       "      <td>-0.097375</td>\n",
       "      <td>-0.216441</td>\n",
       "      <td>0.169326</td>\n",
       "      <td>0.057159</td>\n",
       "      <td>-0.034298</td>\n",
       "      <td>0.431150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011671</td>\n",
       "      <td>0.050762</td>\n",
       "      <td>-0.204316</td>\n",
       "      <td>1.638582</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.030689</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>-0.081300</td>\n",
       "      <td>-0.033844</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.113803</td>\n",
       "      <td>0.108486</td>\n",
       "      <td>0.939266</td>\n",
       "      <td>0.255427</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-0.083422</td>\n",
       "      <td>-0.054675</td>\n",
       "      <td>0.147102</td>\n",
       "      <td>-0.133714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070046</td>\n",
       "      <td>-0.167655</td>\n",
       "      <td>-0.092253</td>\n",
       "      <td>-0.040769</td>\n",
       "      <td>-0.103261</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>-0.103870</td>\n",
       "      <td>0.386899</td>\n",
       "      <td>-0.035554</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.412980</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>0.713474</td>\n",
       "      <td>0.632122</td>\n",
       "      <td>-0.150961</td>\n",
       "      <td>0.043015</td>\n",
       "      <td>-0.116357</td>\n",
       "      <td>-0.071905</td>\n",
       "      <td>0.387462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148249</td>\n",
       "      <td>0.384419</td>\n",
       "      <td>0.134001</td>\n",
       "      <td>0.348973</td>\n",
       "      <td>-0.111628</td>\n",
       "      <td>0.299475</td>\n",
       "      <td>-0.156931</td>\n",
       "      <td>-0.149539</td>\n",
       "      <td>-0.045462</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.550926</td>\n",
       "      <td>-0.192544</td>\n",
       "      <td>-0.174773</td>\n",
       "      <td>-0.017669</td>\n",
       "      <td>-0.130582</td>\n",
       "      <td>-0.190628</td>\n",
       "      <td>-0.139337</td>\n",
       "      <td>-0.100167</td>\n",
       "      <td>0.050681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074378</td>\n",
       "      <td>-0.112425</td>\n",
       "      <td>0.293040</td>\n",
       "      <td>0.790908</td>\n",
       "      <td>-0.222358</td>\n",
       "      <td>-0.167452</td>\n",
       "      <td>-0.106885</td>\n",
       "      <td>-0.157713</td>\n",
       "      <td>0.116547</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.804715</td>\n",
       "      <td>-0.180687</td>\n",
       "      <td>-0.110375</td>\n",
       "      <td>1.339518</td>\n",
       "      <td>-0.122575</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>-0.144777</td>\n",
       "      <td>-0.089144</td>\n",
       "      <td>-0.178694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133782</td>\n",
       "      <td>-0.067391</td>\n",
       "      <td>-0.144996</td>\n",
       "      <td>0.961823</td>\n",
       "      <td>0.545530</td>\n",
       "      <td>1.131453</td>\n",
       "      <td>-0.156405</td>\n",
       "      <td>-0.135552</td>\n",
       "      <td>-0.169803</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85930</th>\n",
       "      <td>85930</td>\n",
       "      <td>-0.113226</td>\n",
       "      <td>-0.118045</td>\n",
       "      <td>-0.222307</td>\n",
       "      <td>-0.168248</td>\n",
       "      <td>-0.160915</td>\n",
       "      <td>-0.168635</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.052695</td>\n",
       "      <td>-0.166531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086500</td>\n",
       "      <td>-0.179051</td>\n",
       "      <td>0.120281</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>-0.130227</td>\n",
       "      <td>-0.138519</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>0.526933</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85931</th>\n",
       "      <td>85931</td>\n",
       "      <td>-0.051178</td>\n",
       "      <td>-0.035326</td>\n",
       "      <td>-0.167132</td>\n",
       "      <td>-0.085977</td>\n",
       "      <td>-0.180994</td>\n",
       "      <td>1.791017</td>\n",
       "      <td>-0.138490</td>\n",
       "      <td>-0.042086</td>\n",
       "      <td>-0.166632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140853</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>-0.164001</td>\n",
       "      <td>0.382978</td>\n",
       "      <td>-0.088951</td>\n",
       "      <td>-0.089313</td>\n",
       "      <td>2.180066</td>\n",
       "      <td>-0.143095</td>\n",
       "      <td>-0.067517</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85932</th>\n",
       "      <td>85932</td>\n",
       "      <td>0.469863</td>\n",
       "      <td>0.312989</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.119212</td>\n",
       "      <td>-0.089325</td>\n",
       "      <td>-0.099193</td>\n",
       "      <td>-0.133834</td>\n",
       "      <td>1.077684</td>\n",
       "      <td>0.220273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061910</td>\n",
       "      <td>-0.124991</td>\n",
       "      <td>-0.149757</td>\n",
       "      <td>1.123994</td>\n",
       "      <td>0.141367</td>\n",
       "      <td>0.225086</td>\n",
       "      <td>-0.125461</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>-0.145158</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85933</th>\n",
       "      <td>85933</td>\n",
       "      <td>0.302072</td>\n",
       "      <td>-0.124257</td>\n",
       "      <td>-0.031438</td>\n",
       "      <td>0.091247</td>\n",
       "      <td>0.318073</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>-0.079065</td>\n",
       "      <td>-0.092398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023317</td>\n",
       "      <td>-0.092640</td>\n",
       "      <td>-0.128483</td>\n",
       "      <td>0.627211</td>\n",
       "      <td>0.042906</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>-0.143885</td>\n",
       "      <td>0.043744</td>\n",
       "      <td>-0.059547</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85934</th>\n",
       "      <td>85934</td>\n",
       "      <td>-0.162606</td>\n",
       "      <td>0.279320</td>\n",
       "      <td>-0.164529</td>\n",
       "      <td>0.080824</td>\n",
       "      <td>-0.157899</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>-0.083612</td>\n",
       "      <td>-0.177969</td>\n",
       "      <td>-0.026611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115318</td>\n",
       "      <td>-0.071921</td>\n",
       "      <td>-0.109116</td>\n",
       "      <td>0.262053</td>\n",
       "      <td>0.021324</td>\n",
       "      <td>-0.137156</td>\n",
       "      <td>-0.129830</td>\n",
       "      <td>-0.084495</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85935 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        X0        X1        X2        X3        X4        X5  \\\n",
       "0          0 -0.062523  0.421099 -0.124768 -0.097375 -0.216441  0.169326   \n",
       "1          1 -0.113803  0.108486  0.939266  0.255427  0.002270 -0.083422   \n",
       "2          2  1.412980 -0.208100  0.713474  0.632122 -0.150961  0.043015   \n",
       "3          3  0.550926 -0.192544 -0.174773 -0.017669 -0.130582 -0.190628   \n",
       "4          4  0.804715 -0.180687 -0.110375  1.339518 -0.122575  0.015235   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "85930  85930 -0.113226 -0.118045 -0.222307 -0.168248 -0.160915 -0.168635   \n",
       "85931  85931 -0.051178 -0.035326 -0.167132 -0.085977 -0.180994  1.791017   \n",
       "85932  85932  0.469863  0.312989  0.850873  0.119212 -0.089325 -0.099193   \n",
       "85933  85933  0.302072 -0.124257 -0.031438  0.091247  0.318073  0.046275   \n",
       "85934  85934 -0.162606  0.279320 -0.164529  0.080824 -0.157899 -0.003044   \n",
       "\n",
       "             X6        X7        X8  ...     X1271     X1272     X1273  \\\n",
       "0      0.057159 -0.034298  0.431150  ... -0.011671  0.050762 -0.204316   \n",
       "1     -0.054675  0.147102 -0.133714  ... -0.070046 -0.167655 -0.092253   \n",
       "2     -0.116357 -0.071905  0.387462  ... -0.148249  0.384419  0.134001   \n",
       "3     -0.139337 -0.100167  0.050681  ... -0.074378 -0.112425  0.293040   \n",
       "4     -0.144777 -0.089144 -0.178694  ... -0.133782 -0.067391 -0.144996   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "85930 -0.141841  0.052695 -0.166531  ... -0.086500 -0.179051  0.120281   \n",
       "85931 -0.138490 -0.042086 -0.166632  ... -0.140853  0.012947 -0.164001   \n",
       "85932 -0.133834  1.077684  0.220273  ... -0.061910 -0.124991 -0.149757   \n",
       "85933  0.037056 -0.079065 -0.092398  ...  0.023317 -0.092640 -0.128483   \n",
       "85934 -0.083612 -0.177969 -0.026611  ... -0.115318 -0.071921 -0.109116   \n",
       "\n",
       "          X1274     X1275     X1276     X1277     X1278     X1279  label  \n",
       "0      1.638582 -0.008674 -0.030689  0.126104 -0.081300 -0.033844    148  \n",
       "1     -0.040769 -0.103261  0.121185 -0.103870  0.386899 -0.035554     33  \n",
       "2      0.348973 -0.111628  0.299475 -0.156931 -0.149539 -0.045462     83  \n",
       "3      0.790908 -0.222358 -0.167452 -0.106885 -0.157713  0.116547     69  \n",
       "4      0.961823  0.545530  1.131453 -0.156405 -0.135552 -0.169803     84  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "85930 -0.042114 -0.130227 -0.138519 -0.002534  0.526933  0.029293     32  \n",
       "85931  0.382978 -0.088951 -0.089313  2.180066 -0.143095 -0.067517    144  \n",
       "85932  1.123994  0.141367  0.225086 -0.125461  0.035168 -0.145158     75  \n",
       "85933  0.627211  0.042906  0.749422 -0.143885  0.043744 -0.059547     46  \n",
       "85934  0.262053  0.021324 -0.137156 -0.129830 -0.084495  0.300120    143  \n",
       "\n",
       "[85935 rows x 1282 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = 1280\n",
    "feature_names = [f\"X{i}\" for i in range(num_features)]\n",
    "\n",
    "raw_content = pd.read_csv(\n",
    "    os.path.join(train_dir, 'nodes.txt'),\n",
    "    sep=\"\\t\",  # tab-separated\n",
    "    header=None,  # no heading row\n",
    "    names=[\"id\", *feature_names, \"label\"],  # set our own names for the columns\n",
    ")\n",
    "raw_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter for rare classes - causes problem\n",
    "# from collections import Counter\n",
    "\n",
    "# node_subjects = raw_content[\"label\"]\n",
    "# retain_classes = [ii[0] for ii in Counter(node_subjects).most_common(100)]\n",
    "\n",
    "# raw_content = raw_content[raw_content.label.isin(retain_classes)]\n",
    "# raw_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 85935, Edges: 68940\n",
      "\n",
      " Node types:\n",
      "  items: [85935]\n",
      "    Features: float32 vector, length 1280\n",
      "    Edge types: items-related->items\n",
      "\n",
      " Edge types:\n",
      "    items-related->items: [68940]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "content_str_subject = raw_content.set_index(\"id\")\n",
    "content_no_subject = content_str_subject.drop(columns=\"label\")\n",
    "G = StellarGraph({\"items\": content_no_subject}, {\"related\": edges})\n",
    "labels = content_str_subject[\"label\"].copy()\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph.layer import GAT\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, feature_extraction, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    node_subjects, train_size=60000, test_size=None, stratify=node_subjects\n",
    ")\n",
    "val_subjects, test_subjects = model_selection.train_test_split(\n",
    "    test_subjects, train_size=10000, test_size=None, stratify=test_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = FullBatchNodeGenerator(G, method=\"gat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "Gc, node_subjects = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 2708, Edges: 5429\n",
      "\n",
      " Node types:\n",
      "  paper: [2708]\n",
      "    Features: float32 vector, length 1433\n",
      "    Edge types: paper-cites->paper\n",
      "\n",
      " Edge types:\n",
      "    paper-cites->paper: [5429]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(Gc.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
