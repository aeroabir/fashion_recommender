{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model for Outfit\n",
    "\n",
    "Create a BERT type model with outfit data (only positive examples) so that we can use this model for transfer learning. \n",
    "\n",
    "1. While it is straight-forward to create BERT type training instance, what to do with [CLS], [SEP] and [MASK] tokens. In a way we are mixing images with textual tokens. We can have a separate learnable embedding for these three tokens but how to mix them with the rest of the images that have a pre-defined embedding or embeddings to be learnt in a different way?\n",
    "\n",
    "2. The size of the vocabulary is large, order of 200,000. The masked language model output would be softmax over this dimension. \n",
    "\n",
    "3. There is no inherent sequence in an outfit and as a result MLM probbaly does not make sense. Instead, Fill-In-The-Blanks is a better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from argparse import Namespace\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/recsys_data/RecSys/fashion/polyvore-dataset/polyvore_outfits/nondisjoint/bert_train.txt\"\n",
    "vocab_file = \"/recsys_data/RecSys/fashion/polyvore-dataset/polyvore_outfits/nondisjoint/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 8\n",
    "max_predictions_per_seq = 3\n",
    "\n",
    "def decode_fn(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "      # Data\n",
    "      record_bytes,\n",
    "      # Schema\n",
    "      {\n",
    "        \"input_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"input_mask\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"segment_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"masked_lm_positions\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_ids\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_weights\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.float32),\n",
    "        \"next_sentence_labels\":\n",
    "            tf.io.FixedLenFeature([1], tf.int64),\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([data_file])\n",
    "dataset = dataset.map(decode_fn)\n",
    "dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list(dataset.as_numpy_iterator())\n",
    "\n",
    "# for batch in dataset.map(decode_fn):\n",
    "#     print(batch)\n",
    "#     sys.exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 8), (32, 8), (32, 3), (32, 3), (32, 3), (32, 1), (32, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_list[0]\n",
    "x['input_ids'].shape, x['input_mask'].shape, x['masked_lm_ids'].shape, x['masked_lm_positions'].shape, x['masked_lm_weights'].shape, x['next_sentence_labels'].shape, x['segment_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[204679,  72700, 204681,  78017, 204680, 204681,  30019, 204680],\n",
       "       [204679, 130657, 204681, 204681, 204680,  56228, 154398, 204680],\n",
       "       [204679, 204681,  49819,  45150, 204680, 204681,  67973, 204680],\n",
       "       [204679,  20558, 204681, 204681, 204680, 184611, 131288, 204680],\n",
       "       [204679, 204681, 100139,  97137, 204680, 204681,  89707, 204680],\n",
       "       [204679,  95687, 204681, 204681, 204680,  43880, 167625, 204680],\n",
       "       [204679,  45008, 204681, 204681, 204680, 165946,  96253, 204680],\n",
       "       [204679,  39454, 204681,  36244, 204680,  32220, 204681, 204680],\n",
       "       [204679,  49575, 204681,  18771, 204680, 126723,  28309, 204680],\n",
       "       [204679,  84908, 204681, 156368, 204680, 157835,  12329, 204680],\n",
       "       [204679,  64614, 204681, 204681, 204680,  12345, 161319, 204680],\n",
       "       [204679,  44450, 162621, 204681, 204680, 132762, 204681, 204680],\n",
       "       [204679, 154831, 203890,  21537, 204680,  69976, 204681, 204680],\n",
       "       [204679,  34198, 204681, 190788, 204680, 184832, 204681, 204680],\n",
       "       [204679, 111903,  60913,  73044, 204680, 204681,  78456, 204680],\n",
       "       [204679,  36001,  50137,  32513, 204680,  52567, 204681, 204680],\n",
       "       [204679,  24177, 204681, 204681, 204680,  97975, 199831, 204680],\n",
       "       [204679,  22550,  47596, 124814, 204680,  70682, 204681, 204680],\n",
       "       [204679, 127257,  28295,  51639, 204680, 204681, 204681, 204680],\n",
       "       [204679, 200849, 163912,  51272, 204680,  68319,  21929, 204680],\n",
       "       [204679, 166237, 117413, 204680, 204681, 169313, 120290, 204680],\n",
       "       [204679,  28019,  83791, 204681, 204680, 129369, 204681, 204680],\n",
       "       [204679, 104435, 204681, 204681, 204680, 159482, 191690, 204680],\n",
       "       [204679, 103405, 118667, 186986, 204680,  35467, 157514, 204680],\n",
       "       [204679, 122795, 204681, 204681, 204680,  88562, 123687, 204680],\n",
       "       [204679, 136978,  60760, 204681, 204680, 204681,  47232, 204680],\n",
       "       [204679, 163908, 204681,  85265, 204680, 204681,  30315, 204680],\n",
       "       [204679, 101098, 152932, 100898, 204680, 146244,  46117, 204680],\n",
       "       [204679, 204681, 134919, 204681, 204680,  48130,  18738, 204680],\n",
       "       [204679, 204681,  92430, 204680, 204681,  41229, 149916, 204680],\n",
       "       [204679, 204681,  22049, 136897, 204680, 101287, 204681, 204680],\n",
       "       [204679, 204681, 183752,   5267, 204680,  74370, 132257, 204680]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65694, 113711,      0],\n",
       "       [  7186,  33879,      0],\n",
       "       [143307, 169821,      0],\n",
       "       [ 25213, 153447,      0],\n",
       "       [144736,  18787,      0],\n",
       "       [ 56758, 118579,      0],\n",
       "       [167311,  76142,      0],\n",
       "       [172050,  81976,      0],\n",
       "       [103198,  28309,      0],\n",
       "       [119081, 156368,      0],\n",
       "       [146483, 100679,      0],\n",
       "       [ 53418, 150250,      0],\n",
       "       [183679,  69688,      0],\n",
       "       [130919,   7954,      0],\n",
       "       [ 73044,  93101,      0],\n",
       "       [ 32513, 178625,      0],\n",
       "       [202741, 118139,      0],\n",
       "       [ 22550,  98684,      0],\n",
       "       [153657, 151641,      0],\n",
       "       [195954,  68319,      0],\n",
       "       [166237,  23611,      0],\n",
       "       [ 91954,  20964,      0],\n",
       "       [183519, 157219,      0],\n",
       "       [103405,  24536,      0],\n",
       "       [153684,  96338,      0],\n",
       "       [ 39237, 169344,      0],\n",
       "       [  2263,  14365,      0],\n",
       "       [ 12869,  46117,      0],\n",
       "       [ 75988,  96779,      0],\n",
       "       [  5359,  68048,      0],\n",
       "       [ 71384, 106392,      0],\n",
       "       [ 71777, 102487,      0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['masked_lm_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 0],\n",
       "       [2, 3, 0],\n",
       "       [1, 5, 0],\n",
       "       [2, 3, 0],\n",
       "       [1, 5, 0],\n",
       "       [2, 3, 0],\n",
       "       [2, 3, 0],\n",
       "       [2, 6, 0],\n",
       "       [2, 6, 0],\n",
       "       [2, 3, 0],\n",
       "       [2, 3, 0],\n",
       "       [3, 6, 0],\n",
       "       [1, 6, 0],\n",
       "       [2, 6, 0],\n",
       "       [3, 5, 0],\n",
       "       [3, 6, 0],\n",
       "       [2, 3, 0],\n",
       "       [1, 6, 0],\n",
       "       [5, 6, 0],\n",
       "       [1, 5, 0],\n",
       "       [1, 4, 0],\n",
       "       [3, 6, 0],\n",
       "       [2, 3, 0],\n",
       "       [1, 3, 0],\n",
       "       [2, 3, 0],\n",
       "       [3, 5, 0],\n",
       "       [2, 5, 0],\n",
       "       [1, 6, 0],\n",
       "       [1, 3, 0],\n",
       "       [1, 4, 0],\n",
       "       [1, 6, 0],\n",
       "       [1, 6, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['masked_lm_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['segment_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"/recsys_data/RecSys/fashion/polyvore-dataset/polyvore_outfits/nondisjoint/vocab.txt\"\n",
    "token_dict, inv_dict = {}, {}\n",
    "with open(vocab_file, 'r') as fr:\n",
    "    for line in fr:\n",
    "        k, v = line.strip().split()\n",
    "        token_dict[k] = int(v)\n",
    "        inv_dict[int(v)] = k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dict[204679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/precomputed\"\n",
    "image_embedding_file = os.path.join(embed_dir, \"effnet_tuned_polyvore.pkl\")\n",
    "with open(image_embedding_file, \"rb\") as fr:\n",
    "    embedding_dict = pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_embedding = np.random.uniform(size=(3,1280))\n",
    "embedding_dict[\"[CLS]\"] = extra_embedding[0]\n",
    "embedding_dict[\"[SEP]\"] = extra_embedding[1]\n",
    "embedding_dict[\"[MASK]\"] = extra_embedding[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_input(inps):\n",
    "    y = []\n",
    "    for ii in range(inps.shape[0]):\n",
    "        toks = inps[ii,:]\n",
    "        toks = [inv_dict[jj] for jj in toks]\n",
    "        vs = np.array([embedding_dict[t] for t in toks])\n",
    "        y.append(vs)\n",
    "    return np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8, 1280)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = convert_to_input(x['input_ids'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/polyvore_outfits\"\n",
    "data_type = \"nondisjoint\" # \"nondisjoint\", \"disjoint\"\n",
    "train_dir = os.path.join(base_dir, data_type)\n",
    "image_dir = os.path.join(base_dir, \"images\")\n",
    "embed_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/precomputed\"\n",
    "train_json = \"train.json\"\n",
    "valid_json = \"valid.json\"\n",
    "test_json = \"test.json\"\n",
    "\n",
    "train_file = \"compatibility_train.txt\"\n",
    "valid_file = \"compatibility_valid.txt\"\n",
    "test_file = \"compatibility_test.txt\"\n",
    "item_file = \"polyvore_item_metadata.json\"\n",
    "outfit_file = \"polyvore_outfit_titles.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 53306, 5000, 10000 outfits in train, validation and test split, respectively\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(train_dir, train_json), 'r') as fr:\n",
    "    train_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(train_dir, valid_json), 'r') as fr:\n",
    "    valid_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(train_dir, test_json), 'r') as fr:\n",
    "    test_pos = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(base_dir, item_file), 'r') as fr:\n",
    "    pv_items = json.load(fr)\n",
    "    \n",
    "with open(os.path.join(base_dir, outfit_file), 'r') as fr:\n",
    "    pv_outfits = json.load(fr)\n",
    "print(f\"Total {len(train_pos)}, {len(valid_pos)}, {len(test_pos)} outfits in train, validation and test split, respectively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 106612, 10000, 20000 examples in train, validation and test split, respectively\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(train_dir, train_file), 'r') as fr:\n",
    "    train_X, train_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        train_y.append(elems[0])\n",
    "        train_X.append(elems[1:])\n",
    "\n",
    "with open(os.path.join(train_dir, valid_file), 'r') as fr:\n",
    "    valid_X, valid_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        valid_y.append(elems[0])\n",
    "        valid_X.append(elems[1:])\n",
    "\n",
    "with open(os.path.join(train_dir, test_file), 'r') as fr:\n",
    "    test_X, test_y = [], []\n",
    "    for line in fr:\n",
    "        elems = line.strip().split()\n",
    "        test_y.append(elems[0])\n",
    "        test_X.append(elems[1:])\n",
    "\n",
    "print(f\"Total {len(train_X)}, {len(valid_X)}, {len(test_X)} examples in train, validation and test split, respectively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284767\n",
      "311548\n",
      "365054\n"
     ]
    }
   ],
   "source": [
    "item_dict = {}\n",
    "for ii, outfit in enumerate(train_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = train_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(len(item_dict))\n",
    "\n",
    "for ii, outfit in enumerate(valid_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = valid_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(len(item_dict))\n",
    "\n",
    "for ii, outfit in enumerate(test_pos):\n",
    "    items = outfit['items']\n",
    "    mapped = test_X[ii]\n",
    "    item_dict.update({jj:kk['item_id'] for jj, kk in zip(mapped, items)})\n",
    "print(len(item_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 8\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 154 item categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 49999/53306 [01:14<00:04, 670.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 100000 examples\n",
      "Total 154 item categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 662.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 10000 examples\n"
     ]
    }
   ],
   "source": [
    "from data_process import BertDataGen\n",
    "\n",
    "extra_embedding = np.random.uniform(size=(1,1280))\n",
    "train_gen = BertDataGen(positive_samples=train_pos,\n",
    "                        item_description=pv_items, \n",
    "                        extra_embedding=extra_embedding,\n",
    "                        max_samples_per_example=1,\n",
    "                        image_embedding_file=os.path.join(embed_dir, \"effnet_tuned_polyvore.pkl\"),\n",
    "                        max_items=max_seq_length,\n",
    "                        batch_size=batch_size,\n",
    "                       )\n",
    "\n",
    "valid_gen = BertDataGen(positive_samples=valid_pos,\n",
    "                        item_description=pv_items, \n",
    "                        extra_embedding=extra_embedding,\n",
    "                        max_samples_per_example=1,\n",
    "                        image_embedding_file=os.path.join(embed_dir, \"effnet_tuned_polyvore.pkl\"),\n",
    "                        max_items=max_seq_length,\n",
    "                        batch_size=batch_size,\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 1280) (32,)\n",
      "(32, 8, 1280) (32,)\n",
      "(32, 8, 1280) (32,)\n",
      "(32, 8, 1280) (32,)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(4):\n",
    "    inps, targs = train_gen[ii]\n",
    "    print(inps.shape, targs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(attention_probs_dropout_prob=0.1, batch_size=32, d_model=768, dff=768, embedding_activation='linear', epochs=100, final_activation='sigmoid', hidden_act='gelu', hidden_dropout_prob=0.1, hidden_size=768, image_data_type='embedding', image_embedding_dim=1280, include_item_categories=False, include_text=False, initializer_range=0.02, inp_dim=1280, inp_seq_len=8, intermediate_size=3072, learning_rate=0.0001, max_position_embeddings=512, model_name='rnn', num_attention_heads=12, num_hidden_layers=12, patience=5, rate=0.1, seed_value=100, text_feature_dim=768, type_vocab_size=2, vocab_size=30522)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"bert_config.json\", 'r') as fr:\n",
    "    bert_config = json.load(fr)\n",
    "\n",
    "# add some extra parameters\n",
    "bert_config[\"model_name\"] = \"rnn\"\n",
    "bert_config[\"inp_seq_len\"] = max_seq_length\n",
    "bert_config[\"inp_dim\"] = 1280\n",
    "bert_config[\"d_model\"] = 768 # 128\n",
    "bert_config[\"include_text\"] = False\n",
    "bert_config[\"text_feature_dim\"] = 768\n",
    "bert_config[\"image_embedding_dim\"] = 1280\n",
    "bert_config[\"include_item_categories\"] = False\n",
    "bert_config[\"image_data_type\"] = \"embedding\"\n",
    "\n",
    "bert_config[\"num_attention_heads\"] = 12\n",
    "bert_config[\"dff\"] = 768 # 128\n",
    "bert_config[\"seed_value\"] = 100\n",
    "bert_config[\"embedding_activation\"] = \"linear\"\n",
    "bert_config[\"rate\"] = 0.1\n",
    "bert_config[\"final_activation\"] = \"sigmoid\"\n",
    "\n",
    "# Traning\n",
    "bert_config[\"learning_rate\"] = 1e-04\n",
    "bert_config[\"epochs\"] = 100\n",
    "bert_config[\"batch_size\"] = 32\n",
    "bert_config[\"patience\"] = 5\n",
    "\n",
    "bert_config = Namespace(**bert_config)\n",
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 1280)]         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowO [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_NotEqual (Tensor [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 8, 1536)           12589056  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 8, 1536)           14161920  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 1536)           6144      \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 1536, 8)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1536, 1)           9         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorF [(None, 1536)]            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 26,758,666\n",
      "Trainable params: 26,755,594\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from bert_modeling import BertModel\n",
    "\n",
    "bml = BertModel(bert_config)\n",
    "bml.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 340s 109ms/step - loss: 0.1801 - auc: 0.4966 - val_loss: 0.1740 - val_auc: 0.5176 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1741 - auc: 0.5319 - val_loss: 0.1711 - val_auc: 0.5746 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 333s 107ms/step - loss: 0.1702 - auc: 0.5958 - val_loss: 0.1679 - val_auc: 0.6217 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1655 - auc: 0.6432 - val_loss: 0.1648 - val_auc: 0.6513 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1602 - auc: 0.6852 - val_loss: 0.1642 - val_auc: 0.6624 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1529 - auc: 0.7269 - val_loss: 0.1632 - val_auc: 0.6749 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1438 - auc: 0.7709 - val_loss: 0.1654 - val_auc: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1310 - auc: 0.8191 - val_loss: 0.1744 - val_auc: 0.6779 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.1051 - auc: 0.8939 - val_loss: 0.2004 - val_auc: 0.6819 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.0879 - auc: 0.9288 - val_loss: 0.2298 - val_auc: 0.6799 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 334s 107ms/step - loss: 0.0670 - auc: 0.9634 - val_loss: 0.2714 - val_auc: 0.6809 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "history = bml.train(train_gen, valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import get_polyvore_data, get_zalando_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 53306, 5000, 10000 outfits in train, validation and test split, respectively\n",
      "Total 106612, 10000, 20000 examples in train, validation and test split, respectively\n",
      "284767\n",
      "311548\n",
      "365054\n"
     ]
    }
   ],
   "source": [
    "pv_config = {\"batch_size\": 32, \"max_seq_len\": 8, \"include_text\": False, \n",
    "             \"image_embedding_dim\": 1280, \n",
    "             \"image_embedding_file\": os.path.join(embed_dir, \"effnet_tuned_polyvore.pkl\"),\n",
    "             \"text_embedding_file\": os.path.join(embed_dir, \"bert_polyvore.pkl\"),\n",
    "             \"text_embedding_dim\": 768,\n",
    "             \"include_item_categories\": False,\n",
    "             \"image_data_type\": \"embedding\",\n",
    "             \"add_cls\": True,\n",
    "             \"extra_embedding\": extra_embedding,\n",
    "            }\n",
    "pv_config = Namespace(**pv_config)\n",
    "pv_train, pv_valid, pv_test = get_polyvore_data(pv_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_auc(data_gen, model):\n",
    "    m = tf.keras.metrics.BinaryAccuracy()\n",
    "    m2 = tf.keras.metrics.AUC()\n",
    "    acc_list = []\n",
    "    pbar = tqdm(range(len(data_gen)))\n",
    "    ys, yhats = [], []\n",
    "    for ii in pbar:\n",
    "        x, y = data_gen[ii]  # batch size\n",
    "        yhat = model(x)\n",
    "        m.update_state(y, yhat)\n",
    "        batch_acc = m.result().numpy()\n",
    "        acc_list.append(batch_acc)\n",
    "        pbar.set_description(\"Batch accuracy %g\" % batch_acc)\n",
    "        ys.append(y)\n",
    "        yhats.append(yhat)\n",
    "    print(f\"Average Accuracy: {np.mean(acc_list)}\")\n",
    "    big_y = np.concatenate(ys, axis=0)\n",
    "    big_yh = np.concatenate(yhats, axis=0)\n",
    "    m2.update_state(big_y, big_yh)\n",
    "    auc = m2.result().numpy()\n",
    "    print(f\"AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.626298: 100%|██████████| 313/313 [00:29<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6173496246337891\n",
      "AUC: 0.6748557686805725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.6286: 100%|██████████| 625/625 [00:57<00:00, 10.95it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6261652112007141\n",
      "AUC: 0.6724649667739868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.637434: 100%|██████████| 3332/3332 [05:09<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.6388095021247864\n",
      "AUC: 0.6875200867652893\n"
     ]
    }
   ],
   "source": [
    "get_accuracy_auc(pv_valid, bml.model)\n",
    "get_accuracy_auc(pv_test, bml.model)\n",
    "get_accuracy_auc(pv_train, bml.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 272541, 7479, 17427 examples in train, validation and test split, respectively\n",
      "90847 training examples, average 3.89 items, max 8 item\n",
      "2493 validation examples, average 4.12 items, max 7 items\n",
      "5809 test examples, average 4.13 items, max 7 item\n"
     ]
    }
   ],
   "source": [
    "from data_process import get_zalando_data\n",
    "\n",
    "zd_config = {\"batch_size\": 32, \"max_seq_len\": 8, \"include_text\": False, \n",
    "             \"image_embedding_dim\": 1280, \n",
    "             \"image_embedding_file\": \"/recsys_data/RecSys/Zalando_Outfit/female/Outfit_Data/precomputed/effnet2_zalando.pkl\",\n",
    "             \"text_embedding_file\": os.path.join(embed_dir, \"bert_polyvore.pkl\"),\n",
    "             \"text_embedding_dim\": 768,\n",
    "             \"include_item_categories\": False,\n",
    "             \"image_data_type\": \"embedding\",\n",
    "             \"add_cls\": True,\n",
    "             \"extra_embedding\": extra_embedding,\n",
    "            }\n",
    "zd_config = Namespace(**zd_config)\n",
    "zd_train, zd_valid, zd_test = get_zalando_data(zd_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.432141: 100%|██████████| 234/234 [00:21<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.43026426434516907\n",
      "AUC: 0.5008366703987122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.43575: 100%|██████████| 545/545 [00:49<00:00, 10.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.4426589012145996\n",
      "AUC: 0.5023459196090698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch accuracy 0.427473: 100%|██████████| 8517/8517 [13:05<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.42716798186302185\n",
      "AUC: 0.5053552985191345\n"
     ]
    }
   ],
   "source": [
    "get_accuracy_auc(zd_valid, bml.model)\n",
    "get_accuracy_auc(zd_test, bml.model)\n",
    "get_accuracy_auc(zd_train, bml.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polyvore-ND</th>\n",
       "      <th>Zalando</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train-AUC</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid-AUC</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-AUC</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Polyvore-ND  Zalando\n",
       "train-AUC        0.738      0.5\n",
       "valid-AUC        0.719      0.5\n",
       "test-AUC         0.721      0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Polyvore-ND\": {\"train-AUC\": 0.738, \"valid-AUC\": 0.719, \"test-AUC\": 0.721},\n",
    "              \"Zalando\": {\"train-AUC\": 0.50, \"valid-AUC\": 0.50, \"test-AUC\": 0.50},\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
