{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Notebook for Saving and Loading Tensorflow Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows how to save and load tensorflow models/checkpoints in Synapse. \r\n",
        "It leverages mssparkutils to mount an ADLS storage to a local folder, \r\n",
        "then save or load models/checkpoints with the mounted folder, the files\r\n",
        "will be saved to/loaded from the ADLS storage.\r\n",
        "\r\n",
        "**This solution should work for any frameworks: tensorflow, pytorch, mxnet, etc.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Before Running:**\r\n",
        "1. Set configuration for Spark pool, details in section [Spark pool configuration](#spark_configuration),\r\n",
        "2. Prepare ADLS storage linked service and account info, details in section [Define parameters and Setup ADLS storage](#adls_storage).\r\n",
        "\r\n",
        "<span id=\"spark_configuration\"></span>\r\n",
        "## Spark pool configuration\r\n",
        "**The configuration must be in the first cell (including markdown and code cells) of the notebook.**\r\n",
        "\r\n",
        "In most cases, we only needs to set the `numExecutors` and `spark.rapids.memory.gpu.reserve`. For very large model such as BERT, `spark.kryoserializer.buffer.max` may also needed. \r\n",
        "For tensorflow models, `spark.executorEnv.TF_FORCE_GPU_ALLOW_GROWTH` should be set to `true`. \r\n",
        "\r\n",
        "Another example with more configuration parameters is as below. The detailed meaning of each parameter is explained in [Spark Configuration](https://spark.apache.org/docs/latest/configuration.html).\r\n",
        "The values here are the best practice for Synapse GPU large pools. For `numExecutors`, it should be less or equal to the number of nodes.\r\n",
        "```\r\n",
        "%%configure -f\r\n",
        "{\r\n",
        "    \"driverMemory\": \"30g\",\r\n",
        "    \"driverCores\": 4,\r\n",
        "    \"executorMemory\": \"60g\",\r\n",
        "    \"executorCores\": 12,\r\n",
        "    \"numExecutors\": 3,\r\n",
        "    \"conf\":{\r\n",
        "        \"spark.rapids.memory.gpu.reserve\": \"10g\",\r\n",
        "        \"spark.executorEnv.TF_FORCE_GPU_ALLOW_GROWTH\": \"true\",\r\n",
        "        \"spark.kryoserializer.buffer.max\": \"2000m\"\r\n",
        "   }\r\n",
        "}\r\n",
        "```\r\n",
        "\r\n",
        "**Below configuration is only needed for GPU pool.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%configure -f\r\n",
        "{\r\n",
        "    \"numExecutors\": 3,\r\n",
        "    \"conf\":{\r\n",
        "        \"spark.rapids.memory.gpu.reserve\": \"10g\",\r\n",
        "        \"spark.executorEnv.TF_FORCE_GPU_ALLOW_GROWTH\": \"true\"\r\n",
        "   }\r\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "36",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:31:04.3129724Z",
              "session_start_time": "2022-08-16T11:31:04.3808631Z",
              "execution_start_time": "2022-08-16T11:34:40.3827339Z",
              "execution_finish_time": "2022-08-16T11:34:40.3831238Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(, 36, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span id=\"adls_storage\"></span>\r\n",
        "## Define parameters and Setup ADLS storage\r\n",
        "\r\n",
        "An ADLS storage is needed for intermediate data and model storing. \r\n",
        "\r\n",
        "- First, setup [Linkded service](https://docs.microsoft.com/en-us/azure/data-factory/concepts-linked-services?context=%2Fazure%2Fsynapse-analytics%2Fcontext%2Fcontext&tabs=data-factory).\r\n",
        "\r\n",
        "- Second, modify `remote_url` and `linked_service_name` according to your service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configure adls store remote url\n",
        "remote_url = \"abfss://default@lijiang1ppesg.dfs.core.windows.net\"\n",
        "linked_service_name = 'lijiang1-synapse-ml-gpu-preprod-ne-WorkspaceDefaultStorage'\n",
        "model_path = 'saved_model'"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:31:04.3145887Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:35:10.9066778Z",
              "execution_finish_time": "2022-08-16T11:35:11.0647166Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount ADLS storage to local"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebookutils import mssparkutils\r\n",
        "\r\n",
        "local_folder = \"/tmp\"  # local folder to mount adls folder\r\n",
        "remote_folder = \"/tmp/\"  # folder in adls to save model\r\n",
        "\r\n",
        "\r\n",
        "def mount_folder():\r\n",
        "    # mount adls folder for model timeline\r\n",
        "    mssparkutils.fs.mount(remote_url + remote_folder, local_folder,\r\n",
        "                          {\"linkedService\": linked_service_name})\r\n",
        "    jobId = mssparkutils.env.getJobId()\r\n",
        "    mount_path = f\"/synfs/{jobId}/{remote_folder}/\"\r\n",
        "    return mount_path\r\n",
        "\r\n",
        "\r\n",
        "def unmount_folder():\r\n",
        "    mssparkutils.fs.unmount(local_folder)\r\n",
        "\r\n",
        "\r\n",
        "mount_path = mount_folder()  # save your model in this folder\r\n",
        "print(mount_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:31:04.3167375Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:35:11.1769204Z",
              "execution_finish_time": "2022-08-16T11:35:27.8723224Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/synfs/36//tmp//\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:37:30.9121402Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:37:31.0351197Z",
              "execution_finish_time": "2022-08-16T11:37:31.1825935Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\r\n",
        "num_classes = 10\r\n",
        "input_shape = (28, 28, 1)\r\n",
        "\r\n",
        "# Load the data and split it between train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
        "\r\n",
        "# Scale images to the [0, 1] range\r\n",
        "x_train = x_train.astype(\"float32\") / 255\r\n",
        "x_test = x_test.astype(\"float32\") / 255\r\n",
        "# Make sure images have shape (28, 28, 1)\r\n",
        "x_train = np.expand_dims(x_train, -1)\r\n",
        "x_test = np.expand_dims(x_test, -1)\r\n",
        "print(\"x_train shape:\", x_train.shape)\r\n",
        "print(x_train.shape[0], \"train samples\")\r\n",
        "print(x_test.shape[0], \"test samples\")\r\n",
        "\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:37:32.4604803Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:37:32.5627826Z",
              "execution_finish_time": "2022-08-16T11:37:33.0856102Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\r\n",
        "epochs = 3\r\n",
        "\r\n",
        "def create_model():\r\n",
        "    model = keras.Sequential(\r\n",
        "        [\r\n",
        "            keras.Input(shape=input_shape),\r\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "            layers.Flatten(),\r\n",
        "            layers.Dropout(0.5),\r\n",
        "            layers.Dense(num_classes, activation=\"softmax\"),\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    model.compile(loss=\"categorical_crossentropy\",\r\n",
        "                optimizer=\"adam\",\r\n",
        "                metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "model = create_model()\r\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:37:33.4538979Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:37:33.5569329Z",
              "execution_finish_time": "2022-08-16T11:37:33.7705012Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                16010     \n=================================================================\nTotal params: 34,826\nTrainable params: 34,826\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1600)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1600)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                16010     \n=================================================================\nTotal params: 34,826\nTrainable params: 34,826\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Save Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath=mount_path + model_path +\r\n",
        "                             '/checkpointfile',\r\n",
        "                             save_weights_only=True,\r\n",
        "                             monitor='val_accuracy',\r\n",
        "                             verbose=2,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "callbacks = [checkpoint]\r\n",
        "\r\n",
        "model.fit(x_train,\r\n",
        "          y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          validation_split=0.1,\r\n",
        "          callbacks=callbacks)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:37:35.6515372Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:37:35.7566958Z",
              "execution_finish_time": "2022-08-16T11:38:07.0774804Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n422/422 [==============================] - 2s 4ms/step - loss: 0.3644 - accuracy: 0.8867 - val_loss: 0.0822 - val_accuracy: 0.9775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\nEpoch 00001: val_accuracy improved from -inf to 0.97750, saving model to /synfs/36//tmp//saved_model/checkpointfile\nEpoch 2/3\n422/422 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9663 - val_loss: 0.0552 - val_accuracy: 0.9847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\nEpoch 00002: val_accuracy improved from 0.97750 to 0.98467, saving model to /synfs/36//tmp//saved_model/checkpointfile\nEpoch 3/3\n422/422 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9735 - val_loss: 0.0494 - val_accuracy: 0.9873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\nEpoch 00003: val_accuracy improved from 0.98467 to 0.98733, saving model to /synfs/36//tmp//saved_model/checkpointfile\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f5818145550>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\r\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=2)\r\n",
        "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:38:18.2000434Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:38:18.2982234Z",
              "execution_finish_time": "2022-08-16T11:38:19.3494404Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0498 - accuracy: 0.9852\nTrained model, accuracy: 98.52%\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint files will be saved in ADLS storage.\r\n",
        "\r\n",
        "![](https://synapseaisolutionsa.blob.core.windows.net/public/imgs/tf_save_load.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = create_model()\r\n",
        "loaded_model.load_weights(mount_path + model_path + '/checkpointfile')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:40:29.0970302Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:40:30.0822526Z",
              "execution_finish_time": "2022-08-16T11:40:31.1320419Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 16, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5b0dd0bcd0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded model\r\n",
        "loss1, acc1 = loaded_model.evaluate(x_test, y_test, verbose=2)\r\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:40:29.2911843Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:40:31.2484837Z",
              "execution_finish_time": "2022-08-16T11:40:32.3572439Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0498 - accuracy: 0.9852\nUntrained model, accuracy: 98.52%\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Save and Load ' + 'Succeed!' if acc1==acc else 'Failed!')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "gpu32",
              "session_id": "36",
              "statement_id": 19,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-08-16T11:41:37.5396617Z",
              "session_start_time": null,
              "execution_start_time": "2022-08-16T11:41:37.6831964Z",
              "execution_finish_time": "2022-08-16T11:41:37.869953Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(gpu32, 36, 19, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save and Load Succeed!\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}