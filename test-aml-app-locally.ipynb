{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutfitGen(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    This generator creates sample outfits using a query item (list)\n",
    "    and adding one item at a time from a list of common items. The \n",
    "    outfit thus created is evaluated by an existing model and the \n",
    "    outfit score is utilized further for creating the best outfit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_embedding_dict,\n",
    "        text_embedding_dict,\n",
    "        batch_size,\n",
    "        max_len,\n",
    "        image_embedding_dim,\n",
    "        query_item,\n",
    "        max_search_item,\n",
    "        shuffle=False,\n",
    "    ):\n",
    "\n",
    "        self.image_embedding_dict = image_embedding_dict\n",
    "        self.text_embedding_dict = text_embedding_dict\n",
    "\n",
    "        common_items = set(self.image_embedding_dict.keys()).intersection(\n",
    "            self.text_embedding_dict.keys())\n",
    "\n",
    "        # working with such large number of items is causing timeout error\n",
    "        # hence downsampling the searchable catalogue of items\n",
    "        rng = np.random.default_rng()\n",
    "        if max_search_item < 1:\n",
    "            max_search_item = int(len(common_items) * max_search_item)\n",
    "            common_items = list(common_items)\n",
    "            sample_indices = rng.choice(\n",
    "                len(common_items), size=max_search_item, replace=False)\n",
    "            sampled_items = [common_items[ii] for ii in sample_indices]\n",
    "\n",
    "        elif max_search_item > 1 and max_search_item < len(common_items):\n",
    "            common_items = list(common_items)\n",
    "            sample_indices = rng.choice(\n",
    "                len(common_items), size=int(max_search_item), replace=False)\n",
    "            sampled_items = [common_items[ii] for ii in sample_indices]\n",
    "\n",
    "        else:\n",
    "            sampled_items = common_items\n",
    "\n",
    "        if type(query_item) is not list:\n",
    "            query_item = [query_item]\n",
    "\n",
    "        X, y = [], []\n",
    "        for item in sampled_items:\n",
    "            if item not in query_item:\n",
    "                X.append([item] + query_item)\n",
    "                y.append(item)\n",
    "\n",
    "        self.X_col = \"X\"\n",
    "        self.y_col = \"y\"\n",
    "        self.df = pd.DataFrame({self.X_col: X, self.y_col: y})\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.image_embedding_dim = image_embedding_dim\n",
    "        self.text_embedding_dim = 768\n",
    "        self.shuffle = shuffle\n",
    "        self.n = len(self.df)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def get_texts(self, item_id):\n",
    "        return self.text_embedding_dict[item_id]\n",
    "\n",
    "    def get_image(self, item_id):\n",
    "        return self.image_embedding_dict[item_id]\n",
    "\n",
    "    def __get_input(self, example):\n",
    "        data = []\n",
    "        items = [x for x in example[: self.max_len]]\n",
    "        for item in items:\n",
    "            image = self.get_image(item)\n",
    "            text = self.get_texts(item)\n",
    "            data.append((text, image))\n",
    "\n",
    "        text_data = [x[0] for x in data]\n",
    "        image_data = [x[1] for x in data]\n",
    "        zero_elem_image = np.zeros(\n",
    "            self.image_embedding_dim)  # np.zeros((1, 1280))\n",
    "        zero_elem_text = np.zeros(self.text_embedding_dim)\n",
    "        zeros_image = [zero_elem_image for _ in range(\n",
    "            self.max_len - len(data))]\n",
    "        zeros_text = [zero_elem_text for _ in range(\n",
    "            self.max_len - len(data))]\n",
    "\n",
    "        return (zeros_image + image_data, zeros_text + text_data)\n",
    "\n",
    "    def __get_output(self, label):\n",
    "        return self.label_dict[label]\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        x_batch = batches[\"X\"].tolist()\n",
    "        y_batch = batches[\"y\"].tolist()\n",
    "\n",
    "        combined = [self.__get_input(x) for x in x_batch]\n",
    "        X_batch = (\n",
    "            np.asarray([x[0] for x in combined]),\n",
    "            np.asarray([x[1] for x in combined]),\n",
    "            # mask,\n",
    "        )\n",
    "        y_batch = np.asarray([int(y) for y in y_batch])\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index *\n",
    "                          self.batch_size: (index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.n / self.batch_size)\n",
    "        # return self.n // self.batch_size\n",
    "\n",
    "\n",
    "def return_top_items(query_item, max_search_item, max_item=8):\n",
    "    if type(query_item) is not list:\n",
    "        query_item = [query_item]\n",
    "    data_gen = OutfitGen(image_embedding_dict=image_embedding_dict,\n",
    "                         text_embedding_dict=text_embedding_dict,\n",
    "                         batch_size=256,\n",
    "                         max_len=max_item,\n",
    "                         image_embedding_dim=1280,\n",
    "                         query_item=query_item,\n",
    "                         max_search_item=max_search_item,\n",
    "                         )\n",
    "    # pbar = tqdm(range(len(data_gen)))\n",
    "    pbar = range(len(data_gen))\n",
    "    current_score = []\n",
    "    for ii in pbar:\n",
    "        x, items = data_gen[ii]\n",
    "        yhat = model(x)\n",
    "        for cs, item in zip(yhat, items):\n",
    "            heapq.heappush(current_score, (1-cs, query_item +\n",
    "                           [str(item)]))  # it's a min-heap\n",
    "    return current_score\n",
    "\n",
    "\n",
    "def filter_outfits(outfits, max_len):\n",
    "    count = 0\n",
    "    filtered = []\n",
    "    while count < max_len:\n",
    "        outfit = heapq.heappop(outfits)\n",
    "        items = outfit[1]\n",
    "        categories = [pv_items[item]['semantic_category'] for item in items]\n",
    "        if len(set(categories)) == len(categories):\n",
    "            filtered.append(items)\n",
    "            count += 1\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def create_outfit(query, max_search_item=1000, max_item=8, beam_length=10):\n",
    "\n",
    "    if type(query) is not list:\n",
    "        query = [query]\n",
    "\n",
    "    # add the first item - only one run\n",
    "    first_score = return_top_items(query, max_search_item)\n",
    "    current_items = filter_outfits(first_score, beam_length)\n",
    "    # plot_current_outfits(current_items, figsize=(10, beam_length * 2))\n",
    "    \n",
    "    print(0, current_items)\n",
    "\n",
    "    for jj in range(len(query)+1, max_item):\n",
    "        all_scores = []\n",
    "        for ii in range(beam_length):\n",
    "            scores_ii = return_top_items(\n",
    "                current_items[ii], max_search_item)\n",
    "            all_scores += scores_ii\n",
    "        # reconstruct current items - with one new item\n",
    "        current_items = filter_outfits(all_scores, beam_length)\n",
    "        print(jj, current_items)\n",
    "        # plot_current_outfits(current_items, figsize=(10 + jj, beam_length * 2))\n",
    "\n",
    "    return current_items\n",
    "\n",
    "\n",
    "def init():\n",
    "    # print(\"This is init\")\n",
    "    \"\"\"\n",
    "    This function is called when the container is initialized/started, typically after create/update of the deployment.\n",
    "    You can write the logic here to perform init operations like caching the model in memory\n",
    "    \"\"\"\n",
    "    global model, image_embedding_dict, text_embedding_dict, pv_items\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"compatibility-rnn_\")\n",
    "\n",
    "    # Example when the model is a file, and the deployment contains multiple models\n",
    "    # https://docs.microsoft.com/en-us/azure/machine-learning/v1/how-to-deploy-advanced-entry-script\n",
    "#     first_model_name = 'compatibility-rnn'\n",
    "#     first_model_version = '1'\n",
    "#     first_model_path = os.path.join(os.getenv(\n",
    "#         'AZUREML_MODEL_DIR'), first_model_name, first_model_version, 'model')\n",
    "    data_type = \"nondisjoint\"\n",
    "    model_type = \"rnn\"\n",
    "    max_seq_len = 8\n",
    "    first_model_path = f\"compatibility_{data_type}_{model_type}_model_{max_seq_len}\"\n",
    "\n",
    "#     second_model_name = 'image-embedding'\n",
    "#     second_model_version = '2'\n",
    "#     image_embedding_file = os.path.join(os.getenv(\n",
    "#         'AZUREML_MODEL_DIR'), second_model_name, second_model_version, 'effnet_tuned_polyvore.pkl')\n",
    "    embed_dir = \"/recsys_data/RecSys/fashion/polyvore-dataset/precomputed\"\n",
    "    image_embedding_file = os.path.join(embed_dir, \"effnet_tuned_polyvore.pkl\")\n",
    "    \n",
    "#     third_model_name = 'text-embedding'\n",
    "#     third_model_version = '2'\n",
    "#     text_embedding_file = os.path.join(os.getenv(\n",
    "#         'AZUREML_MODEL_DIR'), third_model_name, third_model_version, 'bert_polyvore.pkl')\n",
    "    text_embedding_file = os.path.join(embed_dir, \"bert_polyvore.pkl\")\n",
    "\n",
    "#     fourth_model_name = 'item-dict'\n",
    "#     fourth_model_version = '1'\n",
    "#     item_dict_file = os.path.join(os.getenv(\n",
    "#         'AZUREML_MODEL_DIR'), fourth_model_name, fourth_model_version, 'items_polyvore.pkl')\n",
    "    item_dict_file = os.path.join(embed_dir, \"items_polyvore.pkl\")\n",
    "\n",
    "    # does not work\n",
    "    # model_path = Model.get_model_path(model_name='compatibility-rnn')\n",
    "    # image_path = Model.get_model_path(model_name='image-embedding')\n",
    "    # text_path = Model.get_model_path(model_name='text-embedding')\n",
    "\n",
    "    # model_path = os.getenv(\"AZUREML_MODEL_DIR\")\n",
    "    # Load a Tensorflow model from the model folder (there is no single model file)\n",
    "    model = tf.keras.models.load_model(first_model_path)\n",
    "    logging.info(\"Loaded the compatibility model\")\n",
    "\n",
    "    with open(image_embedding_file, \"rb\") as fr:\n",
    "        image_embedding_dict = pickle.load(fr)\n",
    "    logging.info(f\"Loaded {len(image_embedding_dict)} image embeddings\")\n",
    "\n",
    "    with open(text_embedding_file, \"rb\") as fr:\n",
    "        text_embedding_dict = pickle.load(fr)\n",
    "    print(f\"Loaded {len(text_embedding_dict)} text embeddings\")\n",
    "\n",
    "    with open(item_dict_file, \"rb\") as fr:\n",
    "        pv_items = pickle.load(fr)\n",
    "    print(f\"Loaded {len(pv_items)} items ...\")\n",
    "\n",
    "    logging.info(\"Init complete\")\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        inp = json.loads(data)\n",
    "        outfits = create_outfit(query=inp[\"query\"],\n",
    "                                max_search_item=inp[\"max_search_item\"],\n",
    "                                max_item=int(inp[\"max_item\"]),\n",
    "                                beam_length=int(inp[\"beam_length\"]))\n",
    "\n",
    "        logging.info(f\"received data {inp}\")\n",
    "        return f\"Generated outfit: {outfits}\"\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"{\n",
    "    \"query\": \"132621870\",\n",
    "    \"max_search_item\": 100000,\n",
    "    \"max_item\": 5,\n",
    "    \"beam_length\": 2\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 251008 text embeddings\n",
      "Loaded 251008 items ...\n",
      "0 [['132621870', '212822356'], ['132621870', '151036990']]\n",
      "2 [['132621870', '212822356', '184154812'], ['132621870', '212822356', '203338138']]\n",
      "3 [['132621870', '212822356', '184154812', '200172677'], ['132621870', '212822356', '184154812', '185030615']]\n",
      "4 [['132621870', '212822356', '184154812', '200172677', '182992370'], ['132621870', '212822356', '184154812', '200172677', '193960201']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Generated outfit: [['132621870', '212822356', '184154812', '200172677', '182992370'], ['132621870', '212822356', '184154812', '200172677', '193960201']]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init()\n",
    "run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
